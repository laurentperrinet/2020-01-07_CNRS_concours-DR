%!TEX root = perrinet20cnrs.tex
%!TeX TS-program = Lualatex
%!TeX encoding = UTF-8 Unicode
%!TeX spellcheck = fr-FR
%!BIB TS-program = bibtex
% -*- coding: UTF-8; -*-
% vim: set fenc=utf-8
\chapter{Objectifs \& Projet de recherche}
\label{part:outlook}

%\chapter{Perspectives de recherche}

%Cette partie concerne uniquement les rapports à 10 semestres. Vous présentez :
%les objectifs de vos recherches pour les 10 prochains semestres, en les mettant en perspective avec les objectifs de votre unité de recherche et à la politique scientifique du CNRS ;
%et éventuellement vos objectifs concernant les autres facettes de votre activité :
%- enseignement, formation et diffusion de la culture scientifique,
%- transfert technologique, relations industrielles et valorisation,
%- encadrement, animation et management de la recherche.

Comme exposé dans mon rapport d'activité à 10 semestres (chapitre~\ref{chap:projet}, j'ai développé depuis mon intégration au CNRS une thématique étendue dans le domaine de l'étude du système oculomoteur en la focalisant sur l'axe du codage prédictif. 
J'ai présenté dans la partie précédente ces axes de recherche en développant en particulier mes axes de recherche actuels. Focalisons-nous maintenant sur quatre projets particuliers qui posent de façon détaillée les bases prospectives de mon projet de recherche:
\begin{enumerate}
\item Tout d'abord, dans le chapitre~\ref{sec:prediction}, nous avons exposé le modèle de codage prédictif basé sur le mouvement appliqué au problème de l'extrapolation du mouvement. Cette partie va définir un modèle de propagation anisotropique de l'information en le basant sur les méthodes de filtrage particulaire. Nous avons détaillé les résultats obtenus et leur signification au niveau des réponses comportementales.
\item Ensuite, dans la section~\ref{sec:PerrinetBednar15}, nous avons étendu le codage prédictif en étudiant une quantification statistique du champ associatif. Pour montrer la puissance d'une telle représentation, nous l'avons utilisée pour classifier des images, comme par exemple des images contenant des animaux ou non. Cette démarche permet de montrer que ce champ associatif ---et donc un algorithme utilisant un modèle avec des interactions latérales--- permet de construire des algorithmes efficaces de traitement de l'information. Il se pose donc comme une alternative novatrice et complémentaire aux modèles hiérarchiques (de type apprentissage profond) et purement "en avant" qui sont couramment admis dans la littérature~\citep{Serre07}. 
\item Afin de valider à l'échelle neurale de tels algorithmes nous avons proposé dans le chapitre~\ref{sec:spikes} une implantation neurale du modèle décrit dans les sections précédentes. Les résultats montrent qu'un telle implantation n'est pas triviale et demande de définir de façon précise le micro-circuit qui implante au niveau de l'activité neurale les processus inférentiels décrits plus haut.
\item Enfin, dans la section~\ref{sec:free}, j'ai développé la formulation de minimisation de l'énergie libre en l'appliquant au système oculomoteur simplifié, mais pris dans sa globalité. Nous nous sommes attaché en particulier au problème des délais sensori-moteurs dans ce système et avons proposé une méthodologie pour résoudre ce problème. Les résultats ont montré l'émergence de comportement attribués classiquement à des systèmes complexes et que nous pouvons ici décrire de façon économique grâce à la théorie formulée par Karl Friston.
\end{enumerate}


En utilisant ces quatre piliers, nous allons maintenant essayer de dégager les perspectives de recherche qui vont structurer mon programme de recherche futur. L'idée maitresse est (i) d'utiliser les contraintes biologiques (délais, resources limitées) comme des outils pour mieux comprendre le fonctionnement au niveau théorique (ii) d'appliquer ces outils théoriques à des problèmes pratiques, comme la robotique. Ceux-ci sont articulés autour de 3 projets: TRAX, AsyncDrone et ALELOM.%

\section{TRAX: une théorie unifiée du traitement des trajectoires visuelles}


Le mouvement des objets dans les scènes naturelles se fait principalement le long de trajectoires, c'est-à-dire suivant une séquence de positions cohérentes dans le temps par rapport à leur mouvement. Comment les systèmes sensoriels exploitent cette connaissance \emph{a priori} est une question majeure pour les neurosciences computationnelles et la vision par ordinateur. Imaginons un serpent nageant à la surface d'une rivière. Pour extraire et suivre son mouvement, il faut résoudre de difficiles problèmes d'estimation, rendus d'autant plus compliqués par la transparence de l'eau et la non-rigidité du corps du serpent. De plus, les capteurs de mouvement étant limités dans leur extension spatiale, ce corps longiligne peut faire apparaitre une ambiguité sur la vitesse, le \emph{problème de l'ouverture} (voir la section~\ref{sec:prediction}). Il existe de nombreuses solutions à ces problèmes aussi bien en vision par ordinateur qu'en neurosciences computationnelles. Une hypothèse centrale et novatrice du projet TRAX est le fait que le système visuel de bas niveau des mammifères peut les résoudre de façon hautement performante ---tant en termes d'acuité que de robustesse--- grâce à des micro-circuits génériques dont le réseau d'inter-connectivité implante la fonction visuelle et que des règles d'apprentissage adaptent de façon optimale la connectivité aux statistiques des scènes naturelles (voir Figure~\ref{fig:trax}).


%------------------------------------------------------------------------------------------------%
%: see Figure~\ref{fig:trax} 
\begin{figure}[b!]%[p!]%[p!] %h!]%
\centering%
\includegraphics[width=\textwidth]{led-lights-long-exposure-violin.png}

\caption{\textbf{TRAX: poursuivre des trajectoires.} Cette image montre une image à longue exposition d'un violoniste sur lequel on a lixé des LEDs sur son archet [avec permission from \href{http://www.motionexposure.com/Galleries/ViolaViolin/i-CdTcF5V/A}{Stephen Orlando]}. 
Le mouvement complexe des points individuels exhibe un ensemble de trajectoires prototypiques du mouvement rigide d'un objet. Le répertoire de ces mouvements permet d'affiner des algorithmes de détection du mouvement en combinant cohérence spatiale et temporelle.
 } \label{fig:trax} %
\end{figure} %
%------------------------------% 
Ce projet fait actuellement l'objet d'un demande de financement avec des partenaires français (ENS). L'objectif global de ce projet est de fournir un cadre théorique unifié pour comprendre les transformations sensorielles opérant dans les aires corticales visuelles pour permettre d'extraire la trajectoire des contours. Les partenaires impliqués possèdent chacun une expertise forte en neurosciences computationnelles ou en vision par ordinateur, et sont tous spécialisés dans la compréhension des mécanismes de description de bas niveau des images. Nous allons faire collaborer ces chercheurs autour de cette question théorique centrale. Spécifiquement, nous nous centrerons sur l'aire visuelle primaire comme modèle générique de représentation pour les scènes visuelles sous forme de contours élémentaires, ceux-ci étant définis comme des chaines de bords orientés reliés par une probabilité de co-occurence significative. Nous étudierons conjointement les différents problèmes (segmentation, correspondance, ouverture) liés à cette tâche computationnelle pour faire émerger une approche unifiée. Une notion clé est que les trajectoires des contours dans les scènes naturelles suivent des courbes prototypiques que nous pouvons caractériser quantitativement. Nous pourrons alors exploiter ces statistiques pour calculer la probabilité de chaque co-occurence d'appartenir au même contour. 

Pour atteindre cet objectif, la méthode générale consiste à combiner les compétences des partenaires de ce projet en synergie autour de tâches progressivement plus ambitieuses. Premièrement, les statistiques des images naturelles vont nous permettre d'affiner un modèle génératif de synthèse de textures. Ce modèle pourra alors servir d'algorithme dans le processus de détection de contours, mais aussi de modèle du comportement humain. Ensuite, nous inclurons ces trajectoires dans un modèle de flux optique. La principale nouveauté de cette formulation est de considérer ce dernier non pas comme l'estimation du mouvement des pixels, mais basé sur la trajectoire des contours. Enfin, nous testerons grâce à des textures synthétiques la précision avec laquelle ces modèles permettent de comprendre les prédictions obtenues sur un modèle neuromimétique mais aussi par rapport à la neuro-physiologie, en particulier pour valider les règles d'apprentissage non-supervisé. Cette méthode nous permettra alors de proposer un modèle unifié du traitement sensoriel des contours basé sur l'étude des trajectoires dans les scènes naturelles, un progrès significatif pour la vision par ordinateur et les neurosciences computationnelles.

\section{AsyncDrone: application du codage événementiel à la robotique}
%
%Robotics is a rapidly evolving technology that allows for fast, low-risk and low-cost tasks with a worldwide market of over 80 billion dollars over the next few years. In particular, aerial robots, also known as drones, provide a breakthrough to easily image and access all sorts of terrains and situations and are useful for instance in surveillance and forensics, emergency industrial inspection or a search and rescue operation. A major difficulty for their global acceptance is the difficulty for controlling their flight and interacting with them. 
%Indeed, aerial robots are generally operated using a (central) ground station which is not compatible with the time pressure required by emergency conditions, for instance when rescuing a person out of reach with the ground station. This PhD project aims at concealing such obstacles and construct an aerial robot which is able to be autonomously and interactively controlled by simple human gestures, for instance that of a rescuer. The main scientific challenges are (i) to embed in the aerial robot all the electronics for the visual system from the retina to the control signals to the propellers, (ii) to very quickly recognize a variety of simple gestures on-board using a neuromimetic architecture and (iii) to make the robot react in real time to these gestures. As such, this project is inter-disciplinary by positively combining advanced algorithms from event-based bio-inspired computer vision and the latest technology in aerial robots.
%First, the project will aim at using bio-inspired methods to remove the three mentioned obstacles. Biological vision, contrary to conventional processing, is not using frame-based information or clock-based processing. Indeed, it is computationally more efficient to take full advantage of the dynamic nature of the visual scene: Biological vision is relying on neurones working in parallel networks and coding the spatio-temporal information of the visual scene into asynchronous spike trains. Thus, biological visual processing, starting at the retina, is totally asynchronous and event-driven, and their artificial counterparts can be efficiently modelled [1]. Event-based dynamic vision provide a novel and efficient way for encoding light and its temporal variations by registering and transmitting only the changes when they occur. Neuromorphic vision sensors mimic biological visual processing by using an array of interconnected neurons to simulate the neural network [2] and such systems can output dynamic decision making signals which can be used to steer the propellers. 
La robotique est une technologie en évolution rapide qui permet d'accomplir des tâches rapides, à faible risque et faible coût avec un marché mondial estimé à plus de 80 milliards de dollars au cours des prochaines années. En particulier, les robots aériens, également connus sous le nom de drones, offrent une percée technologique pour facilement imager et accéder à toutes sortes de terrains et situations et sont utiles par exemple dans la surveillance et la médecine légale, l'inspection industrielle d'urgence ou une opération de recherche et de sauvetage. Une difficulté majeure pour leur acceptation globale est la difficulté de contrôler leur vol et d'interagir avec eux.
En effet, les robots aériens sont généralement exploités au moyen d'une station au sol (centrale) qui n'est pas compatible avec la pression temporelle requise par des conditions d'urgence, par exemple lors du sauvetage d'une personne hors de la portée avec la station au sol. Ce projet vise à surmonter de tels obstacles et à construire un robot aérien capable d'être contrôlé de manière autonome et interactive par de simples gestes humains, par exemple celui d'un sauveteur. Les principaux enjeux scientifiques sont (i) d'intégrer dans le robot aérien tous les composants électroniques depuis le système visuel (rétine) jusqu'aux signaux de commande des hélices, (ii) de reconnaître très rapidement une variété de gestes simples à bord en utilisant une architecture neuromimétique et (iii) faire réagir le robot en temps réel à ces gestes. En tant que tel, ce projet est interdisciplinaire en combinant positivement des algorithmes avancés de la vision par ordinateur bio-inspirée événementielle et des dernières technologies dans les robots aériens.

Tout d'abord, le projet visera à utiliser des méthodes bio-inspirées pour éliminer les trois obstacles mentionnés. La vision biologique, contrairement au traitement conventionnel, n'utilise pas l'information basée sur l'image ou le traitement basé sur l'horloge. En effet, il est plus efficace sur le plan informatique de tirer pleinement parti de la nature dynamique de la scène visuelle: la vision biologique repose sur des neurones travaillant en réseaux parallèles et codant l'information spatio-temporelle de la scène visuelle en trains asynchrones. Ainsi, le traitement visuel biologique, à partir de la rétine, est totalement asynchrone et événementiel, et leurs homologues artificiels peuvent être efficacement modélisés. La vision dynamique basée sur le codage événementiel fournit un moyen novateur et efficace pour encoder la lumière et ses variations temporelles en enregistrant et en transmettant uniquement les changements lorsqu'ils se produisent. Les capteurs de vision neuromorphique imitent le traitement biologique visuel en utilisant un réseau de neurones interconnectés pour simuler le réseau neuronal et de tels systèmes peuvent produire des signaux de prise de décision dynamiques qui peuvent être utilisés pour diriger les hélices.
%

%Second, we intend to detect simple human gestures based on the semaphore system which is based on characteristic hand and body movements. These are well adapted as they are simple, fast and efficient to categorize thanks to their unique spatio-temporal signatures. Previous authors used computationally intensive frame-based visual processing and classifiers to recognize patterns made with different face poses and hand gestures onboard UAVs [3]. Differently, we hypothesize that dynamic human gestures contain characteristic statistics with respect to still images such that they are more easy to categorize within these neuromimetic systems.
%As a consequence, the present PhD proposal will provide with a method to control an aerial robot with hand and body gesture using a bio-inspired asynchronous electronic architecture. We will first design the neuromorphic retina able to generate spikes adapted to gesture vision. Then, the PhD project will focus on signal processing methods to identify human presence and associate efficiently series of spikes to its body movement. The electronic architecture processing the visual signals will be strongly inspired by the architecture of neural networks, and therefore will be preferably using clock-less microcontrollers (such as the Verilog-based Tiempo clockless 16-bit microcontroller) or at least an asynchronous computational unit (such as FPGA). An algorithm will then transform the perceived body movement into control order to the aerial robot. Last but not least, experimental studies will be conducted using the MoCap Vicon system inside the Marseilles? Flying Arena.
De plus, nous avons l'intention de détecter des gestes humains simples basés sur le système des ``sémaphores'' qui est basé sur des mouvements caractéristiques de la main et du corps. Ils sont bien adaptés car ils sont simples, rapides et efficaces à catégoriser grâce à leurs signatures spatio-temporelles uniques. Les auteurs précédents ont utilisé des traitements et des classificateurs visuels basés sur des calculs intensifs pour reconnaître des motifs réalisés avec des prises de vue des visage et des gestes des mains à bord des drones. Par ailleurs, nous supposons que les gestes humains dynamiques contiennent des statistiques caractéristiques concernant les images fixes (voir projet TRAX ci-dessus), de sorte qu'elles sont plus faciles à catégoriser au sein de ces systèmes neuromimétiques. %En conséquence, ce projet fournira une méthode pour contrôler un robot aérien avec le geste de la main et du corps en utilisant une architecture électronique asynchrone bio-inspirée. Nous commencerons par concevoir la rétine neuromorphique capable de générer des pointes adaptées à la vision gestuelle. Ensuite, le projet de doctorat se concentrera sur les méthodes de traitement des signaux pour identifier la présence humaine et associer efficacement une série de pointes à son mouvement corporel. L'architecture électronique traitant les signaux visuels sera fortement inspirée par l'architecture des réseaux neuronaux et sera donc de préférence utilisant des microcontrôleurs sans horloge (comme le microcontrôleur Time-clock 16 bits sans temps Verilog) ou au moins une unité de calcul asynchrone Tels que FPGA). Un algorithme transformera alors le mouvement du corps perçu en ordre de commande au robot aérien. Enfin, des études expérimentales seront réalisées à l'aide du système MoCap Vicon à l'intérieur de l'aréna volante de Marseille.
%[1] R. Benosman , S.-H. Leng , C. Clercq , C. Bartolozzi & M. Srinivasan (2012) ?Asynchronous frameless event-based optical flow?, Neural Networks - Elsevier
%[2] S.-C. Liu & T. Delbruck (2010) ?Neuromorphic sensory systems?, Current opinion in neurobiology - Elsevier
%[3] J. Nagi, A. Giusti, G. A. Di Caro, L. M. Gambardella (2014) ?HRI in the Sky, Controlling UAVs using Face Poses and Hand Gestures?, HRI

Ce projet est proposé en collaboration avec Franck Ruffier (ISM, CNRS/AMU, UMR7287) et avec la SATT Sud-Est. C'est une application directe de nos expertises scientifiques communes vers une application concrète : un robot aérien contrôlable par des mouvements humains. Nous nous sommes associés avec la Société d'Accélération du Transfert de Technologies Sud Est (SATT Sud Est) qui a pour mission le transfert des résultats issus des laboratoires publics et de ses actionnaires, notamment par la maturation et le transfert de technologies vers des entreprises et le soutien à la création d'entreprises innovantes. Son activité consiste à protéger, rendre plus mature et licencier des résultats de recherche afin de permettre à des entreprises d'adopter une technologie mieux adaptée aux enjeux industriels. Par la dimension d'application industrielle de ce projet spécifique, le rôle de la SATT sera essentiel pour permettre de concrétiser ce projet en évaluant la brevetabilité et les attentes du marché. Victor Boutin, l'étudiant que nous avons choisi fera dans ce but un stage à la SATT Sud-Est en dernière année de thèse. Ce temps permettra d'établir des contacts avec les acteurs susceptibles être concernés (pôle de compétitivité Safe, pompiers, sécurité civile, PMEs et entreprises de drones comme Smart Aerial Machines, Novadem ou Parrot) et d'organiser des sessions  de démonstration montrant l'interaction entre le robot et l'opérateur.

\section{ALELOM: Active inference, Learning and Event-based coding for Lightweight Oculo-Motor control}
 
%The oculo-motor activity is an essential component of man and animal behaviour, subserving most of daily displacements and interactions with objects, devices or people. By moving gaze with the eyes, the center of sight is constantly and actively moving around during all waking time. 
%The {\bf active vision paradigm}~\cite{friston2012perceptions}, recently developed in neuroscience, relies on a longstanding history of probabilistic modelling in signal processing and control \cite{Kalman1960,Baum1966,friston1994statistical}. 
%What we primarily do is reconsider with care the problem faced by a living system when having to react at very sort notice in a threatening environment with limited resources. Critical signals need to be interpreted fast, and many others need to be ignored. 
%How robust and efficient such decision making is achieved is not only important for neuroscience, but also for robotics, which faces similar constraints. 
Comme nous l'avons vu, l'activité oculo-motrice est une composante essentielle du comportement de l'homme et des animaux, conditionnant la plupart des déplacements quotidiens et des interactions avec des objets, des dispositifs ou des personnes. En déplaçant le regard avec les yeux, le centre de vision est constamment en train de se déplacer activement. Le paradigme de vision actif, développé récemment en neuroscience, s'appuie sur une longue histoire de modélisation probabiliste du traitement et du contrôle du signal.
Dans ce projet, nous voulons reconsidérer avec soin ce problème auquel est confronté chaque système vivant en considérant exactement les contraintes naturelles lorsque nous devons réagir de façon très précoce dans un environnement restreint et avec des ressources limitées. Ainsi, les signaux les plus saillants doivent être interprétés rapidement, et les autres doivent être ignorés.
La robustesse et l'efficacité de cette prise de décision ne sont pas seulement importantes pour les neurosciences, mais aussi pour la robotique qui fait face à des contraintes similaires.

%Taking guidance from the biological observations, the idea is to consider the natural strategies adopted to deal with limited sensors and limited computing resources: how use at best low sensory bitrate and noisy sensors? how much memory use, what motor decisions make to maintain a consistent model of the outside scene? The active vision approach considers an organization of the visual space in objects (or causes), whose presence and localization is continuously verified by visual inspection. For instance, saccades are considered in this theory to be probing a particular region of the visual space, with the objective of reducing the uncertainty about the identity and place of particular objects. This theory takes for granted that an a priori knowledge exists on all possible objects and locations but also for the repertoire of movements.
En s'inspirant des observations biologiques, l'idée est de considérer les stratégies naturelles adoptées pour tenir compte de capteurs limités avec des ressources informatiques limitées. Explicitement, comment utiliser au mieux un débit binaire faible et les capteurs bruités? Comment optimiser l'utilisation de la mémoire pour maintenir un modèle cohérent de la scène extérieure? Sous ces contraintes, l'approche de vision active considère une organisation de l'espace visuel comme l'association spatio-temporelle d'objets (ou causes), dont la présence et la localisation sont continuellement vérifiées par inspection visuelle. Par exemple, les saccades sont considérées dans cette théorie comme sondant une région particulière de l'espace visuel~\citep{Friston12}, dans le but de réduire l'incertitude sur l'identité et le lieu des objets particuliers. Cette théorie prend pour acquis qu'une connaissance a priori existe sur tous les objets et lieux possibles, mais aussi pour le répertoire des mouvements (en lien donc avec le projet TRAX).

%The active vision framework is general enough to apply both in man, animal and machine vision, opening new avenues in (i) landmark extraction/scene construction in robot navigation, (ii) modeling the learning of visuo-motor contingencies and (iii) developing social robot acceptance through man-machine visual interaction. {\bf Our general objective is the design of an artificial saccadic exploration module, to be plugged-in on an on-board controller}. The model should be general enough to address the construction and maintenance of a visual scene through saccades, and compatible with the use of lightweight sensors and event-based coding. Our aim is also to gather researchers from neuroscience, applied mathematics, psychology and robotics to revisit motor control paradigms at the light of recent neurophysiological findings.
Ce cadre de travail est assez général pour s'appliquer à la vision de l'homme, de l'animal et de la machine, ouvrant de nouvelles perspectives dans (i) l'extraction de repères / la construction de scènes dans la navigation robot, (ii) la modélisation de l'apprentissage des contingences visuo-motrices et (iii) l'acceptation du robot social par l'interaction visuelle homme-machine. Notre objectif spécifique est la conception d'un module d'exploration saccadique artificiel sur un contrôleur embarqué. Le modèle devrait être assez général pour permettre la construction et l'exploration d'une scène visuelle par saccades, tout en restant compatible avec l'utilisation de capteurs légers et le codage événementiel. Notre objectif est également de rassembler des chercheurs des neurosciences, des mathématiques appliquées, de la psychologie et de la robotique pour revoir les paradigmes de contrôle moteur à la lumière des résultats neurophysiologiques récents. Ces acteurs sont présent au niveau local et nous avons récemment déposé une demande de financement nationale (ANR) et locale dans le cadre du renforcement des équipes marseillaise de neurosciences computationnelles.

\section{Conclusion: Inférence active, de la prédiction à l'anticipation}
%: = théorique
%: 1.tout n'est que réduction de free-energy / renforcement avec Laurent Madelain (URECA)
%: de marr à friston : ma visite à UCL

Les trois projets que nous avons présentés et qui sont financés ou en cours de financement s'attachent à inscrire les avancées théoriques sous la contrainte d'une implantation neuro-mimétique et active. 
À ce titre, le principe de Miminimisation de l'\'Energie Libre (MEL) que nous avons exposé dans ce manuscrit (voir section~\ref{sec:free}) constitue une base théorique essentielle pour consolider la compréhension de ces mécanismes neuronaux. En particulier, ce principe permet d'implanter des mécanismes de codage prédictif à différentes échelles, de l'aire corticale au système oculomoteur complet. Un objectif à moyen terme est d'unifier les différentes approches que nous avons exposées dans le domaine spatial (Section~\ref{sec:PerrinetBednar15}) ou spatio-temporel~\citep{Perrinet12} (Section~\ref{sec:prediction}) pour les étendre à une approche commune en terme de minimisation de l'énergie libre (voir Figure~\ref{fig:trax}). Une telle approche nous permettra en particulier de mettre en synergie des sources d'information de modalités différentes. En effet, s'il est important de comprendre les aspects prédictifs isolément (d'un contour local en fonction du contexte voisin, d'un point le long d'un trajectoire), il semble essentiel dans le futur de pouvoir en comprendre les interactions, comme par exemple le mouvement de contours le long de trajectoires complexes.

%: 2. truismes: mais permet de définir e qu'est la prédictio/ l'anticipation et de mélanger des milieux qui ne se connaissent pas 
%: 3. temps?
Un avantage du principe de MEL et de la formalisation proposée par Karl Friston est d'avoir défini une terminologie claire et univoque. Par exemple, alors que la prédiction est considéré comme un ajustement de l'état présent en fonction du contexte passé (en utilisant par exemple l'inférence statistique), le concept d'anticipation est alors défini de façon claire comme un changement \emph{prévu dans le futur} de l'état du système. Le principe de MEL permet ainsi de dépasser des problèmes de dialogues entre certaines disciplines qui ont freiné le développement des approches computationnelles de codage prédictif. En particulier, un objectif de recherche à long terme est d'étudier la notion de temps dans les processus neuronaux et en particulier dans le cadre du système oculomoteur. En effet, nous avons vu précédemment dans la section~\ref{sec:free} qu'une difficulté majeure dans le système oculomoteur est l'existence de délais sensori-moteurs. Si nous avons considéré dans le modèle précédent des délais fixes, ceux-ci sont plus généralement variables, et de plus peuvent exister entre des niveaux de traitement différents (ce que nous avons omis dans le modèle précédemment). Prendre en compte ces délais en toute généralité permettrait de s'attaquer explicitement à un problème essentiel en neurosciences et qui est le plus souvent éludé: l'activité que je mesure sur un neurone se réfère-t-elle au temps présent? Ou alors il correspond au temps auquel j'ai reçu l'information sensorielle, au temps auquel j'anticipe de fournir l'action motrice? Bien sûr, il semblerait que les temps auxquels se réfèrent chaque point d'activité neurale, vus de façon globale, constitue un continuum autour du temps présent et permette de situer l'agent dans un contexte temporel. Ce contexte constitue alors la base de mécanismes essentiels et pour lesquelles nous ne connaissons encore de réponse, comme les mécanismes de mémoire, ou la coordination des flux d'information dans l'ensemble du système nerveux central. C'est cet objectif de recherche fondamentale que j'espère poursuivre dans les 10 prochaines semestres autour des trois projets que j'ai défini plus haut.